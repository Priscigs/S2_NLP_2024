{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXhjY9dGwJls"
      },
      "source": [
        "NOMBRES: Fátima Priscilla \n",
        "\n",
        "APELLIDOS: González Sandoval\n",
        "\n",
        "CARNE: 20689\n",
        "\n",
        "FECHA: 24 de agosto de 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7nnvCPLh5Ms"
      },
      "source": [
        "**Ejercicio 1**\n",
        "Con los datos de la clase de lunes, cálcule PPMI, pero aplicando Lapace Smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r3aTZXJeiFAI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Computer</td>\n",
              "      <td>data</td>\n",
              "      <td>result</td>\n",
              "      <td>pie</td>\n",
              "      <td>sugar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cherry</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>44260</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Strawberry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Digital</td>\n",
              "      <td>1670</td>\n",
              "      <td>1683</td>\n",
              "      <td>85</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Information</td>\n",
              "      <td>3325</td>\n",
              "      <td>3982</td>\n",
              "      <td>378</td>\n",
              "      <td>512</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5\n",
              "0          NaN   Computer       data     result        pie      sugar\n",
              "1       Cherry          2          8          9      44260         25\n",
              "2   Strawberry          0          0          1          5         19\n",
              "3      Digital       1670       1683         85          5          4\n",
              "4  Information       3325       3982        378        512         13"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = '../PMI_Ejercicio/pmi_ejercicio.xlsx'\n",
        "df_PMI = pd.read_excel(file_path)\n",
        "df_PMI.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/8f/4tqfct110qxbk9qrh28g1lpr0000gn/T/ipykernel_70723/3563902525.py:17: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  pmi = np.log2(Pxy / (Px[:, None] * Py[None, :]))\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Computer</th>\n",
              "      <th>data</th>\n",
              "      <th>result</th>\n",
              "      <th>pie</th>\n",
              "      <th>sugar</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nan</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cherry</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.32097</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Strawberry</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.968558</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>9.165963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Digital</th>\n",
              "      <td>2.438572</td>\n",
              "      <td>2.266840</td>\n",
              "      <td>1.548496</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.319637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Information</th>\n",
              "      <td>2.180820</td>\n",
              "      <td>2.257976</td>\n",
              "      <td>2.437457</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.554236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0            Computer      data    result      pie     sugar\n",
              "nan                                                         \n",
              "Cherry       0.000000  0.000000  0.000000  0.32097  0.000000\n",
              "Strawberry   0.000000  0.000000  2.968558  0.00000  9.165963\n",
              "Digital      2.438572  2.266840  1.548496  0.00000  0.319637\n",
              "Information  2.180820  2.257976  2.437457  0.00000  0.554236"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Limpia de datos\n",
        "df_PMI.columns = df_PMI.iloc[0]  \n",
        "df_PMI = df_PMI.drop(df_PMI.index[0])  \n",
        "df_PMI = df_PMI.set_index(df_PMI.columns[0]) \n",
        "\n",
        "df_PMI = df_PMI.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Aplicar suavizado de Laplace sumando 1 a cada cuenta\n",
        "laplace_df_PMI = df_PMI + 1\n",
        "\n",
        "total_sum = laplace_df_PMI.sum().sum()\n",
        "\n",
        "Px = laplace_df_PMI.sum(axis=1) / total_sum  \n",
        "Py = laplace_df_PMI.sum(axis=0) / total_sum  \n",
        "Pxy = laplace_df_PMI / total_sum  \n",
        "\n",
        "pmi = np.log2(Pxy / (Px[:, None] * Py[None, :]))\n",
        "\n",
        "ppmi = np.maximum(pmi, 0)\n",
        "\n",
        "# Convertir a DataFrame para facilitar la visualización\n",
        "ppmi_df_PMI = pd.DataFrame(ppmi, index=laplace_df_PMI.index, columns=laplace_df_PMI.columns)\n",
        "\n",
        "ppmi_df_PMI.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzRf6sNDiF1v"
      },
      "source": [
        "**Ejercicio 2**\n",
        "\n",
        "POC para crear información de entreno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o3CzZjlIiPA2"
      },
      "outputs": [],
      "source": [
        "#Librerías que necesitarán\n",
        "import io\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "%load_ext tensorboard\n",
        "SEED = 42\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e0LLReSPiVxw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens: ['the', 'wind', 'crosses', 'the', 'brown', 'land', 'unheard']\n",
            "Vocabulario: {'algo importante para que no explote el programa': 0, 'the': 1, 'wind': 2, 'crosses': 3, 'brown': 4, 'land': 5, 'unheard': 6}\n",
            "Secuencia de ejemplo: [1, 2, 3, 1, 4, 5, 6]\n",
            "Positive Skip-Grams: [[6, 5], [1, 3], [6, 4], [4, 1], [4, 5], [2, 1], [1, 5], [4, 3], [1, 3], [4, 6], [1, 2], [3, 1], [5, 4], [2, 1], [1, 2], [3, 4], [5, 1], [3, 2], [3, 1], [2, 3], [5, 6], [1, 4]]\n"
          ]
        }
      ],
      "source": [
        "sentece = \"The wind Crosses the brown land unheard\" #De mis poemas fav. The waste land de T.S Elliot\n",
        "tokens = tf.keras.preprocessing.text.text_to_word_sequence(sentece) #tokenizar\n",
        "vocab, index = {}, 1 #arreglo vocabulario, empezar indice en 1\n",
        "vocab[\"algo importante para que no explote el programa\"] = 0\n",
        "\n",
        "#Llene el arreglo para vocabulario\n",
        "for word in tokens:\n",
        "    if word not in vocab:\n",
        "        vocab[word] = index\n",
        "        index += 1\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "example_sequence = [vocab[word] for word in tokens]\n",
        "window_size = 2\n",
        "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "    example_sequence,\n",
        "    vocabulary_size=vocab_size,\n",
        "    window_size=window_size,\n",
        "    negative_samples=0\n",
        ") #rellene esta area como le sea pertinente)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Vocabulario:\", vocab)\n",
        "print(\"Secuencia de ejemplo:\", example_sequence)\n",
        "print(\"Positive Skip-Grams:\", positive_skip_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loA64ZR0k3L0",
        "outputId": "a8e28e58-e1bd-492c-c92b-13539c7a74c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 5): (unheard, land)\n",
            "(1, 3): (the, crosses)\n",
            "(6, 4): (unheard, brown)\n",
            "(4, 1): (brown, the)\n",
            "(4, 5): (brown, land)\n"
          ]
        }
      ],
      "source": [
        "#Resultados\n",
        "inverse_vocab = {index: token for token, index in vocab.items()}\n",
        "for target, context in positive_skip_grams[:5]:\n",
        "  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GdtE3R10lcAG"
      },
      "outputs": [],
      "source": [
        "target_word, context_word = positive_skip_grams[0]\n",
        "# Escoja un numero para muestras negativos (que no pertenence al contexto)\n",
        "num_ns = 4\n",
        "\n",
        "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
        "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "    true_classes=context_class,  # clase que debe ser muestreada como positiva (que pertenece al contexto)\n",
        "    num_true=1,\n",
        "    num_sampled=num_ns,\n",
        "    unique=True,\n",
        "    range_max=vocab_size,  # [0, vocab_size]\n",
        "    seed=SEED,\n",
        "    name=\"negative_sampling\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WcxIUEmpmUt7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
            "['wind', 'the', 'brown', 'crosses']\n"
          ]
        }
      ],
      "source": [
        "print(negative_sampling_candidates)\n",
        "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OpVHwBkDAurO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
            " 0.01212381]\n"
          ]
        }
      ],
      "source": [
        "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=vocab_size) #funcion que construye la tabla de muestreo en forma de frecuencias\n",
        "print(sampling_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t3iK0LesA5Lu"
      },
      "outputs": [],
      "source": [
        "negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1) #se agrega una dimension para poder concatenar\n",
        "context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
        "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "target = tf.squeeze(target_word)\n",
        "context = tf.squeeze(context)\n",
        "label = tf.squeeze(label)\n",
        "\n",
        "#Listo! asi se prepara la info para entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNHYhsn6D-jS",
        "outputId": "6dee158e-2219-440c-f8bd-62d824c1489b"
      },
      "outputs": [],
      "source": [
        "#Informacion a utilizar:\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "omu8ON00A_0H"
      },
      "outputs": [],
      "source": [
        "#Paso 1: cree una funcion que estandarice el texto como ya hemos hecho e incrustela en una capa de Tensorflow (TextVectorization)\n",
        "def vect(input_text):\n",
        "    lowercase = tf.strings.lower(input_text)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "    return tf.strings.regex_replace(stripped_html, f'[{re.escape(string.punctuation)}]', '')\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=vect,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=50  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y64v-qOFDhDj"
      },
      "outputs": [],
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h5OvM9GDrRt"
      },
      "outputs": [],
      "source": [
        "#Paso 2: Usando la POC de creacion de datos de entreno, defina una funcion para este proceso\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMmxeZPbEMOg"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "# Vectorize the data in text_ds.\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()\n",
        "sequences = list(text_vector_ds.as_numpy_iterator())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsgvY5hZE5X4"
      },
      "outputs": [],
      "source": [
        "#El siguiente codigo es el modelo Word2Vec usando lo que ya han hecho. Sin embargo, deben agregar la metrica de similitud que vimos en clase, a la cual deben llamar dots\n",
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = layers.Embedding(vocab_size,\n",
        "                                       embedding_dim)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "\n",
        "\n",
        "    # dots: (batch, context)\n",
        "    return dots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCX5lVLdFN-D"
      },
      "outputs": [],
      "source": [
        "#Entrenar modelo y definir CategoricalCrossEntropy como funcion de perdida. Mostrar el print de accuracy y loss. Si deciden presentar sus resultados en tensorboard, adjuntar capturas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
