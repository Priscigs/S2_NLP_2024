{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_zPatjVVhE"
      },
      "source": [
        "NOMBRE: Priscilla González\n",
        "\n",
        "\n",
        "CARNE: 20689\n",
        "\n",
        "\n",
        "FECHA: 12.10.24\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBAfJsqmZhWg"
      },
      "source": [
        "**Objetivo**: La idea de esta práctica es que exploren el desarrollo de un proceso de cuatización. Para esto, deben cubrir lo que se vio en clase:\n",
        "1. Efectuar el proceso de cuantización.\n",
        "2. Determinar su error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oWDLcURIVZqs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tensor = torch.tensor([[-0.6870,  0.2607, -0.7718,  0.0841],\n",
        "                       [ 0.6558, -1.1711, -1.0713,  0.2405],\n",
        "                       [ 1.4967, -0.6928,  0.7961, -1.4614],\n",
        "                       [ 0.5689, -0.5227, -1.3111, -0.8343]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mt-KTIVrVt12"
      },
      "outputs": [],
      "source": [
        "rmin = test_tensor.min().item()\n",
        "rmax = test_tensor.max().item()\n",
        "qmin = -128\n",
        "qmax = 127\n",
        "\n",
        "scale = (rmax - rmin) / (qmax - qmin)\n",
        "zero_point = round(qmin - (rmin / scale))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmin: -1.461400032043457, rmax: 1.4967000484466553\n",
            "Scale: 0.011600392472510244\n",
            "Zero point: -2\n"
          ]
        }
      ],
      "source": [
        "print(f\"rmin: {rmin}, rmax: {rmax}\")\n",
        "print(f\"Scale: {scale}\")\n",
        "print(f\"Zero point: {zero_point}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "quantized_tensor = torch.round(test_tensor / scale + zero_point).clamp(qmin, qmax).to(torch.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "deq_tensor = (quantized_tensor.float() - zero_point) * scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor cuantizado:\n",
            "tensor([[ -61,   20,  -69,    5],\n",
            "        [  55, -103,  -94,   19],\n",
            "        [ 127,  -62,   67, -128],\n",
            "        [  47,  -47, -115,  -74]], dtype=torch.int8)\n",
            "\n",
            "Tensor descuantizado:\n",
            "tensor([[-0.6844,  0.2552, -0.7772,  0.0812],\n",
            "        [ 0.6612, -1.1716, -1.0672,  0.2436],\n",
            "        [ 1.4965, -0.6960,  0.8004, -1.4616],\n",
            "        [ 0.5684, -0.5220, -1.3108, -0.8352]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensor cuantizado:\")\n",
        "print(quantized_tensor)\n",
        "print(\"\\nTensor descuantizado:\")\n",
        "print(deq_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tensor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Así como se vio en clase, definan una proceso de linear quantization para test_tensor\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Para llevar esto a acabo, debe encontrar la escala: scale = rmax-rmin/qmax-qmin.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Trabajando con pytorch int8 (para mapear a int4) qmax=127 y qmin=-128.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#Resultado del tensor cuantizado:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m quantized_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m([[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m],\n\u001b[1;32m     13\u001b[0m                            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m],\n\u001b[1;32m     14\u001b[0m                            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m],\n\u001b[1;32m     15\u001b[0m                            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m77\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint8)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#Resultado del tensor descuantizado:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m deq_tensor \u001b[38;5;241m=\u001b[39m tensor([[\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m     18\u001b[0m                      [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m     19\u001b[0m                      [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m],\n\u001b[1;32m     20\u001b[0m                      [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m]])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
          ]
        }
      ],
      "source": [
        "#Así como se vio en clase, definan una proceso de linear quantization para test_tensor\n",
        "#Para llevar esto a acabo, debe encontrar la escala: scale = rmax-rmin/qmax-qmin.\n",
        "#Trabajando con pytorch int8 (para mapear a int4) qmax=127 y qmin=-128.\n",
        "#zero_point = qmin-(rmin/scale).\n",
        "#Con esta informacion ya pueden proceder a trabaja la cuantización lineal.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Resultado del tensor cuantizado:\n",
        "quantized_tensor = tensor([[-77, -77, -77, -77],\n",
        "                           [-77, -77, -77, -77],\n",
        "                           [-77, -77, -77, -77],\n",
        "                           [-77, -77, -77, -77]], dtype=torch.int8)\n",
        "#Resultado del tensor descuantizado:\n",
        "deq_tensor = tensor([[0., 0., 0., 0.],\n",
        "                     [0., 0., 0., 0.],\n",
        "                     [0., 0., 0., 0.],\n",
        "                     [0., 0., 0., 0.]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y2z0ujTYdgf"
      },
      "source": [
        "Con la parte anterior correcta, ya pueden proceder a trabajar lo siguiente:\n",
        "\n",
        "1. Investigar Symmetric mode quantization.\n",
        "2. per-channel quantization.\n",
        "3. per-group quantization.\n",
        "\n",
        "Para cada uno de estos, explicar su funcionamiento y cuando puede ser conveniente usarlos respecto a las otras técnicas.\n",
        "\n",
        "Finalmente, desarrollar cada uno de la misma manera en que se trabajo la cuantización lineal. (Estos tres son casos especiales de la cuantización lineal, por lo que deberían solo hacer cambios especificos al código de la primera parte).\n",
        "\n",
        "\n",
        "Responda la siguiente pregunta: ¿Aquí estamos trabajando post-training quantization o quantization-aware training?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Symmetric Mode Quantization\n",
        "\n",
        "Para este caso, los valores proceden a cuantizarse, de esta forma se encuentran valores tanto positivos como negativos con respecto a 0. Por lo tanto, los valores mínimos y máximos del tensor original se cuantizan de forma simétrica. Entonces, es bastante conveniente usarlo cuando los valores tienen una distribución centrada alrededor de 0, como se trata ReLU.\n",
        "\n",
        " - https://www.ai-bites.net/model-quantization-in-deep-learning/#:~:text=Symmetric%20quantization%20is%20exactly%20what,point%20is%20set%20to%200.\n",
        "\n",
        "### Per-channel Quantization\n",
        "\n",
        "Este es comúnmente usado en capas convolucionales ya que cada dimensión del tensor contiene su propia cuantización, en este caso, es el scale y el zero_point.\n",
        "\n",
        " - https://medium.com/@curiositydeck/quantization-granularity-aec2dd7a0bb4\n",
        "\n",
        "### Per-group Quantization\n",
        "\n",
        "Esta técnica es casi igual a la antrior, solo que en este caso, lo que se hace es que se agrupan varias dimensiones y no solamente 1. Entonces, de igual forma, se le aplica su propia cuantización por dimensión. Esta técnica ayuda bastante cuando se trata de aplicaciones con bastantes capas en redes neuronales.\n",
        "\n",
        "- https://medium.com/@curiositydeck/quantization-granularity-aec2dd7a0bb4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
